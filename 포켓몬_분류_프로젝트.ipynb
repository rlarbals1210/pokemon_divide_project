{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39bd3502-e6bb-4039-8905-cfef36588858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스(타입): ['Bug' 'Dark' 'Dragon' 'Electric' 'Fairy' 'Fighting' 'Fire' 'Flying'\n",
      " 'Ghost' 'Grass' 'Ground' 'Ice' 'Normal' 'Poison' 'Psychic' 'Rock' 'Steel'\n",
      " 'Water']\n",
      "샘플 라벨: [0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0]\n",
      "Epoch 1/100\n",
      "     21/Unknown \u001b[1m13s\u001b[0m 274ms/step - accuracy: 0.0678 - loss: 0.4691"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bgs99\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:164: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 482ms/step - accuracy: 0.0618 - loss: 0.3844 - val_accuracy: 0.0988 - val_loss: 0.3260\n",
      "Epoch 2/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 371ms/step - accuracy: 0.1329 - loss: 0.3032 - val_accuracy: 0.1481 - val_loss: 0.2837\n",
      "Epoch 3/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 367ms/step - accuracy: 0.1577 - loss: 0.2783 - val_accuracy: 0.1975 - val_loss: 0.2802\n",
      "Epoch 4/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 364ms/step - accuracy: 0.2056 - loss: 0.2629 - val_accuracy: 0.2099 - val_loss: 0.2749\n",
      "Epoch 5/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 353ms/step - accuracy: 0.2117 - loss: 0.2525 - val_accuracy: 0.2284 - val_loss: 0.2725\n",
      "Epoch 6/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 375ms/step - accuracy: 0.2535 - loss: 0.2419 - val_accuracy: 0.2222 - val_loss: 0.2698\n",
      "Epoch 7/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 1s/step - accuracy: 0.2720 - loss: 0.2332 - val_accuracy: 0.2222 - val_loss: 0.2683\n",
      "Epoch 8/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 381ms/step - accuracy: 0.2875 - loss: 0.2238 - val_accuracy: 0.2284 - val_loss: 0.2672\n",
      "Epoch 9/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 354ms/step - accuracy: 0.3107 - loss: 0.2175 - val_accuracy: 0.2469 - val_loss: 0.2661\n",
      "Epoch 10/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 355ms/step - accuracy: 0.3617 - loss: 0.2097 - val_accuracy: 0.2407 - val_loss: 0.2648\n",
      "Epoch 11/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 362ms/step - accuracy: 0.3771 - loss: 0.2030 - val_accuracy: 0.2346 - val_loss: 0.2643\n",
      "Epoch 12/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 386ms/step - accuracy: 0.4096 - loss: 0.1966 - val_accuracy: 0.2469 - val_loss: 0.2642\n",
      "Epoch 13/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 352ms/step - accuracy: 0.3879 - loss: 0.1914 - val_accuracy: 0.2346 - val_loss: 0.2639\n",
      "Epoch 14/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 351ms/step - accuracy: 0.4513 - loss: 0.1861 - val_accuracy: 0.2222 - val_loss: 0.2633\n",
      "Epoch 15/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 374ms/step - accuracy: 0.4513 - loss: 0.1807 - val_accuracy: 0.2346 - val_loss: 0.2637\n",
      "Epoch 16/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 482ms/step - accuracy: 0.4621 - loss: 0.1780 - val_accuracy: 0.2469 - val_loss: 0.2631\n",
      "Epoch 17/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 355ms/step - accuracy: 0.4668 - loss: 0.1702 - val_accuracy: 0.2469 - val_loss: 0.2641\n",
      "Epoch 18/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 372ms/step - accuracy: 0.4621 - loss: 0.1687 - val_accuracy: 0.2469 - val_loss: 0.2632\n",
      "Epoch 19/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 364ms/step - accuracy: 0.4869 - loss: 0.1671 - val_accuracy: 0.2469 - val_loss: 0.2638\n",
      "Epoch 20/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 354ms/step - accuracy: 0.5100 - loss: 0.1594 - val_accuracy: 0.2469 - val_loss: 0.2651\n",
      "Epoch 21/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 381ms/step - accuracy: 0.4853 - loss: 0.1601 - val_accuracy: 0.2346 - val_loss: 0.2638\n",
      "Epoch 22/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 369ms/step - accuracy: 0.5224 - loss: 0.1546 - val_accuracy: 0.2407 - val_loss: 0.2651\n",
      "Epoch 23/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 366ms/step - accuracy: 0.5379 - loss: 0.1524 - val_accuracy: 0.2346 - val_loss: 0.2649\n",
      "Epoch 24/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 365ms/step - accuracy: 0.5085 - loss: 0.1515 - val_accuracy: 0.2407 - val_loss: 0.2667\n",
      "Epoch 25/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 359ms/step - accuracy: 0.5518 - loss: 0.1471 - val_accuracy: 0.2469 - val_loss: 0.2670\n",
      "Epoch 26/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 380ms/step - accuracy: 0.5564 - loss: 0.1424 - val_accuracy: 0.2654 - val_loss: 0.2669\n",
      "Epoch 27/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 375ms/step - accuracy: 0.5811 - loss: 0.1403 - val_accuracy: 0.2469 - val_loss: 0.2678\n",
      "Epoch 28/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 362ms/step - accuracy: 0.5719 - loss: 0.1373 - val_accuracy: 0.2593 - val_loss: 0.2680\n",
      "Epoch 29/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 384ms/step - accuracy: 0.5626 - loss: 0.1341 - val_accuracy: 0.2469 - val_loss: 0.2690\n",
      "Epoch 30/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 374ms/step - accuracy: 0.5811 - loss: 0.1304 - val_accuracy: 0.2407 - val_loss: 0.2707\n",
      "Epoch 31/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 368ms/step - accuracy: 0.6213 - loss: 0.1299 - val_accuracy: 0.2407 - val_loss: 0.2705\n",
      "Epoch 32/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 4s/step - accuracy: 0.6090 - loss: 0.1289 - val_accuracy: 0.2469 - val_loss: 0.2708\n",
      "Epoch 33/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 488ms/step - accuracy: 0.5997 - loss: 0.1256 - val_accuracy: 0.2531 - val_loss: 0.2712\n",
      "Epoch 34/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 478ms/step - accuracy: 0.6105 - loss: 0.1243 - val_accuracy: 0.2284 - val_loss: 0.2729\n",
      "Epoch 35/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 471ms/step - accuracy: 0.5920 - loss: 0.1227 - val_accuracy: 0.2346 - val_loss: 0.2729\n",
      "Epoch 36/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 471ms/step - accuracy: 0.6229 - loss: 0.1188 - val_accuracy: 0.2407 - val_loss: 0.2738\n",
      "Epoch 37/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 471ms/step - accuracy: 0.6167 - loss: 0.1179 - val_accuracy: 0.2469 - val_loss: 0.2747\n",
      "Epoch 38/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 480ms/step - accuracy: 0.5889 - loss: 0.1168 - val_accuracy: 0.2531 - val_loss: 0.2747\n",
      "Epoch 39/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 487ms/step - accuracy: 0.6229 - loss: 0.1178 - val_accuracy: 0.2407 - val_loss: 0.2748\n",
      "Epoch 40/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 471ms/step - accuracy: 0.6198 - loss: 0.1153 - val_accuracy: 0.2407 - val_loss: 0.2765\n",
      "Epoch 41/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 452ms/step - accuracy: 0.5981 - loss: 0.1152 - val_accuracy: 0.2407 - val_loss: 0.2779\n",
      "Epoch 42/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 441ms/step - accuracy: 0.6352 - loss: 0.1115 - val_accuracy: 0.2469 - val_loss: 0.2788\n",
      "Epoch 43/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 461ms/step - accuracy: 0.6244 - loss: 0.1100 - val_accuracy: 0.2346 - val_loss: 0.2795\n",
      "Epoch 44/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 428ms/step - accuracy: 0.6461 - loss: 0.1075 - val_accuracy: 0.2346 - val_loss: 0.2793\n",
      "Epoch 45/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 452ms/step - accuracy: 0.6553 - loss: 0.1034 - val_accuracy: 0.2407 - val_loss: 0.2815\n",
      "Epoch 46/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 3s/step - accuracy: 0.6600 - loss: 0.1056 - val_accuracy: 0.2222 - val_loss: 0.2800\n",
      "Epoch 47/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 452ms/step - accuracy: 0.6569 - loss: 0.1038 - val_accuracy: 0.2346 - val_loss: 0.2821\n",
      "Epoch 48/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 456ms/step - accuracy: 0.6569 - loss: 0.1036 - val_accuracy: 0.2346 - val_loss: 0.2828\n",
      "Epoch 49/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 438ms/step - accuracy: 0.6847 - loss: 0.1009 - val_accuracy: 0.2222 - val_loss: 0.2844\n",
      "Epoch 50/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 464ms/step - accuracy: 0.6584 - loss: 0.1048 - val_accuracy: 0.2407 - val_loss: 0.2841\n",
      "Epoch 51/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 441ms/step - accuracy: 0.6507 - loss: 0.0999 - val_accuracy: 0.2346 - val_loss: 0.2842\n",
      "Epoch 52/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 434ms/step - accuracy: 0.6553 - loss: 0.0993 - val_accuracy: 0.2222 - val_loss: 0.2854\n",
      "Epoch 53/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 441ms/step - accuracy: 0.6631 - loss: 0.0963 - val_accuracy: 0.2284 - val_loss: 0.2870\n",
      "Epoch 54/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 420ms/step - accuracy: 0.6584 - loss: 0.0967 - val_accuracy: 0.2222 - val_loss: 0.2879\n",
      "Epoch 55/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 430ms/step - accuracy: 0.6600 - loss: 0.0946 - val_accuracy: 0.2284 - val_loss: 0.2868\n",
      "Epoch 56/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 446ms/step - accuracy: 0.6739 - loss: 0.0929 - val_accuracy: 0.2284 - val_loss: 0.2897\n",
      "Epoch 57/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 421ms/step - accuracy: 0.6832 - loss: 0.0902 - val_accuracy: 0.2160 - val_loss: 0.2891\n",
      "Epoch 58/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 426ms/step - accuracy: 0.6847 - loss: 0.0923 - val_accuracy: 0.2407 - val_loss: 0.2930\n",
      "Epoch 59/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 430ms/step - accuracy: 0.6646 - loss: 0.0920 - val_accuracy: 0.2160 - val_loss: 0.2894\n",
      "Epoch 60/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 437ms/step - accuracy: 0.6739 - loss: 0.0895 - val_accuracy: 0.2346 - val_loss: 0.2916\n",
      "Epoch 61/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 429ms/step - accuracy: 0.6909 - loss: 0.0898 - val_accuracy: 0.2222 - val_loss: 0.2916\n",
      "Epoch 62/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 410ms/step - accuracy: 0.6785 - loss: 0.0861 - val_accuracy: 0.2346 - val_loss: 0.2933\n",
      "Epoch 63/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 407ms/step - accuracy: 0.6878 - loss: 0.0884 - val_accuracy: 0.2222 - val_loss: 0.2946\n",
      "Epoch 64/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 423ms/step - accuracy: 0.6909 - loss: 0.0884 - val_accuracy: 0.2222 - val_loss: 0.2955\n",
      "Epoch 65/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 519ms/step - accuracy: 0.6739 - loss: 0.0880 - val_accuracy: 0.2284 - val_loss: 0.2965\n",
      "Epoch 66/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 461ms/step - accuracy: 0.7079 - loss: 0.0842 - val_accuracy: 0.2284 - val_loss: 0.2958\n",
      "Epoch 67/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 435ms/step - accuracy: 0.6692 - loss: 0.0828 - val_accuracy: 0.2284 - val_loss: 0.2993\n",
      "Epoch 68/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 425ms/step - accuracy: 0.6955 - loss: 0.0815 - val_accuracy: 0.2037 - val_loss: 0.2999\n",
      "Epoch 69/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 411ms/step - accuracy: 0.6986 - loss: 0.0813 - val_accuracy: 0.2099 - val_loss: 0.3007\n",
      "Epoch 70/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 456ms/step - accuracy: 0.6692 - loss: 0.0815 - val_accuracy: 0.2099 - val_loss: 0.3013\n",
      "Epoch 71/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 428ms/step - accuracy: 0.7017 - loss: 0.0814 - val_accuracy: 0.2037 - val_loss: 0.3016\n",
      "Epoch 72/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 410ms/step - accuracy: 0.6708 - loss: 0.0833 - val_accuracy: 0.2037 - val_loss: 0.3021\n",
      "Epoch 73/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 430ms/step - accuracy: 0.6723 - loss: 0.0824 - val_accuracy: 0.2160 - val_loss: 0.3034\n",
      "Epoch 74/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 428ms/step - accuracy: 0.6909 - loss: 0.0785 - val_accuracy: 0.2099 - val_loss: 0.3036\n",
      "Epoch 75/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 439ms/step - accuracy: 0.6785 - loss: 0.0796 - val_accuracy: 0.2222 - val_loss: 0.3063\n",
      "Epoch 76/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 443ms/step - accuracy: 0.7079 - loss: 0.0803 - val_accuracy: 0.2099 - val_loss: 0.3058\n",
      "Epoch 77/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 413ms/step - accuracy: 0.7172 - loss: 0.0749 - val_accuracy: 0.2099 - val_loss: 0.3060\n",
      "Epoch 78/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 429ms/step - accuracy: 0.7094 - loss: 0.0765 - val_accuracy: 0.2160 - val_loss: 0.3074\n",
      "Epoch 79/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 415ms/step - accuracy: 0.6739 - loss: 0.0777 - val_accuracy: 0.2037 - val_loss: 0.3074\n",
      "Epoch 80/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 391ms/step - accuracy: 0.6893 - loss: 0.0768 - val_accuracy: 0.2099 - val_loss: 0.3079\n",
      "Epoch 81/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 393ms/step - accuracy: 0.7465 - loss: 0.0728 - val_accuracy: 0.2160 - val_loss: 0.3087\n",
      "Epoch 82/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 402ms/step - accuracy: 0.7017 - loss: 0.0751 - val_accuracy: 0.2099 - val_loss: 0.3095\n",
      "Epoch 83/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 415ms/step - accuracy: 0.7202 - loss: 0.0751 - val_accuracy: 0.2099 - val_loss: 0.3105\n",
      "Epoch 84/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 398ms/step - accuracy: 0.6754 - loss: 0.0765 - val_accuracy: 0.2160 - val_loss: 0.3095\n",
      "Epoch 85/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 389ms/step - accuracy: 0.7094 - loss: 0.0717 - val_accuracy: 0.2160 - val_loss: 0.3142\n",
      "Epoch 86/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 4s/step - accuracy: 0.7002 - loss: 0.0756 - val_accuracy: 0.2160 - val_loss: 0.3120\n",
      "Epoch 87/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 420ms/step - accuracy: 0.7002 - loss: 0.0693 - val_accuracy: 0.2222 - val_loss: 0.3142\n",
      "Epoch 88/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 381ms/step - accuracy: 0.7172 - loss: 0.0727 - val_accuracy: 0.2346 - val_loss: 0.3135\n",
      "Epoch 89/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 411ms/step - accuracy: 0.7218 - loss: 0.0723 - val_accuracy: 0.2222 - val_loss: 0.3145\n",
      "Epoch 90/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 393ms/step - accuracy: 0.7434 - loss: 0.0689 - val_accuracy: 0.2099 - val_loss: 0.3153\n",
      "Epoch 91/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 416ms/step - accuracy: 0.7218 - loss: 0.0699 - val_accuracy: 0.2284 - val_loss: 0.3168\n",
      "Epoch 92/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 394ms/step - accuracy: 0.6986 - loss: 0.0715 - val_accuracy: 0.2037 - val_loss: 0.3171\n",
      "Epoch 93/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 386ms/step - accuracy: 0.7110 - loss: 0.0698 - val_accuracy: 0.2222 - val_loss: 0.3159\n",
      "Epoch 94/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 396ms/step - accuracy: 0.7125 - loss: 0.0703 - val_accuracy: 0.2284 - val_loss: 0.3178\n",
      "Epoch 95/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 386ms/step - accuracy: 0.6986 - loss: 0.0665 - val_accuracy: 0.2284 - val_loss: 0.3185\n",
      "Epoch 96/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 380ms/step - accuracy: 0.7388 - loss: 0.0696 - val_accuracy: 0.2160 - val_loss: 0.3205\n",
      "Epoch 97/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 377ms/step - accuracy: 0.7295 - loss: 0.0678 - val_accuracy: 0.2160 - val_loss: 0.3197\n",
      "Epoch 98/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 382ms/step - accuracy: 0.7156 - loss: 0.0671 - val_accuracy: 0.2222 - val_loss: 0.3230\n",
      "Epoch 99/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 3s/step - accuracy: 0.6986 - loss: 0.0692 - val_accuracy: 0.2407 - val_loss: 0.3235\n",
      "Epoch 100/100\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 415ms/step - accuracy: 0.7295 - loss: 0.0658 - val_accuracy: 0.2222 - val_loss: 0.3249\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 59s/step\n",
      "실제 타입: ['Rock', 'Ice']\n",
      "예측 타입: []\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "csv_path = \"./pokemon.csv\" \n",
    "img_dir = \"./images\"    \n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "\n",
    "df[\"image_path\"] = df[\"Name\"].apply(lambda x: os.path.join(img_dir, f\"{x}.png\"))\n",
    "\n",
    "df = df[df[\"image_path\"].apply(os.path.exists)]\n",
    "\n",
    "\n",
    "df[\"Type2\"] = df[\"Type2\"].fillna(\"\")\n",
    "df[\"labels\"] = df.apply(lambda x: [x[\"Type1\"]] if x[\"Type2\"] == \"\" else [x[\"Type1\"], x[\"Type2\"]], axis=1)\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "y = mlb.fit_transform(df[\"labels\"])\n",
    "\n",
    "print(\"클래스(타입):\", mlb.classes_)\n",
    "print(\"샘플 라벨:\", y[0])\n",
    "\n",
    "\n",
    "train_df, val_df, y_train, y_val = train_test_split(df, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "def load_dataset(df, labels, batch_size=BATCH_SIZE):\n",
    "    def gen():\n",
    "        for img_path, label in zip(df[\"image_path\"], labels):\n",
    "            img = tf.keras.preprocessing.image.load_img(img_path, target_size=IMG_SIZE)\n",
    "            img = tf.keras.preprocessing.image.img_to_array(img) / 255.0\n",
    "            yield img, label\n",
    "\n",
    "    ds = tf.data.Dataset.from_generator(\n",
    "        gen,\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(IMG_SIZE[0], IMG_SIZE[1], 3), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(len(mlb.classes_),), dtype=tf.float32)\n",
    "        )\n",
    "    )\n",
    "    return ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_ds = load_dataset(train_df, y_train)\n",
    "val_ds = load_dataset(val_df, y_val)\n",
    "\n",
    "base_model = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "preds = Dense(len(mlb.classes_), activation=\"sigmoid\")(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=preds)\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=100\n",
    ")\n",
    "\n",
    "sample_img = val_df.iloc[0][\"image_path\"]\n",
    "img = tf.keras.preprocessing.image.load_img(sample_img, target_size=IMG_SIZE)\n",
    "img_arr = tf.keras.preprocessing.image.img_to_array(img)/255.0\n",
    "img_arr = np.expand_dims(img_arr, axis=0)\n",
    "\n",
    "pred = model.predict(img_arr)[0]\n",
    "pred_labels = [mlb.classes_[i] for i, v in enumerate(pred) if v > 0.5]\n",
    "\n",
    "print(\"실제 타입:\", val_df.iloc[0][\"labels\"])\n",
    "print(\"예측 타입:\", pred_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fcd03f-083f-488e-8173-50558f7b67f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
