{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 254 images belonging to 4 classes.\n",
      "Found 62 images belonging to 4 classes.\n",
      "\n",
      "[INFO] 감지된 클래스 수: 4 → ['Weezing 복사본', 'Wigglytuff 복사본', 'Zapdos 복사본', 'Zubat 복사본']\n",
      "Epoch 1/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 398ms/step - accuracy: 0.7283 - loss: 0.7405 - val_accuracy: 0.9516 - val_loss: 0.1927\n",
      "Epoch 2/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 301ms/step - accuracy: 0.9488 - loss: 0.1639 - val_accuracy: 0.9839 - val_loss: 0.0663\n",
      "Epoch 3/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 324ms/step - accuracy: 0.9764 - loss: 0.0659 - val_accuracy: 0.9839 - val_loss: 0.0504\n",
      "Epoch 4/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 292ms/step - accuracy: 0.9921 - loss: 0.0251 - val_accuracy: 0.9677 - val_loss: 0.0611\n",
      "Epoch 5/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 342ms/step - accuracy: 0.9921 - loss: 0.0228 - val_accuracy: 0.9839 - val_loss: 0.0351\n",
      "Epoch 6/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 340ms/step - accuracy: 1.0000 - loss: 0.0103 - val_accuracy: 0.9839 - val_loss: 0.0339\n",
      "Epoch 7/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 299ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 0.9839 - val_loss: 0.0358\n",
      "Epoch 8/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 295ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.9839 - val_loss: 0.0346\n",
      "Epoch 9/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 298ms/step - accuracy: 1.0000 - loss: 0.0047 - val_accuracy: 0.9677 - val_loss: 0.0382\n",
      "Epoch 10/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 302ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.9677 - val_loss: 0.0365\n",
      "Epoch 11/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 304ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.9839 - val_loss: 0.0346\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 577ms/step\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "   Weezing 복사본       0.93      1.00      0.97        14\n",
      "Wigglytuff 복사본       1.00      1.00      1.00        19\n",
      "    Zapdos 복사본       1.00      1.00      1.00        17\n",
      "     Zubat 복사본       1.00      0.92      0.96        12\n",
      "\n",
      "           accuracy                           0.98        62\n",
      "          macro avg       0.98      0.98      0.98        62\n",
      "       weighted avg       0.98      0.98      0.98        62\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import os\n",
    "\n",
    "# ── 경로/하이퍼파라미터 ──────────────────────────────────────────────\n",
    "base_dir   = './Test_File'   # 클래스별 하위폴더 포함\n",
    "img_size   = (224, 224)\n",
    "batch_size = 32\n",
    "epochs     = 20\n",
    "num_classes = 3                         # 클래스 개수\n",
    "\n",
    "# ── 데이터 제너레이터 (훈련/검증 8:2 분할) ─────────────────────────────\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training',       # 학습용\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',     # 검증용\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "\n",
    "# 클래스 정보\n",
    "class_indices = train_generator.class_indices       # {'classA':0, ...}\n",
    "idx_to_class = [None]*len(class_indices)\n",
    "for k, v in class_indices.items():\n",
    "    idx_to_class[v] = k\n",
    "num_classes = len(idx_to_class)\n",
    "print(f\"\\n[INFO] 감지된 클래스 수: {num_classes} → {idx_to_class}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ── 사전학습 모델(MobileNetV2) + 커스텀 분류기 ────────────────────────\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False  # 특성 추출 모드\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# ── 콜백 (EarlyStopping, 체크포인트) ──────────────────────────────────\n",
    "early_stop  = EarlyStopping(patience=5, restore_best_weights=True, monitor='val_loss')\n",
    "model_path  = 'best_animal_model.keras'\n",
    "checkpoint  = ModelCheckpoint(model_path, save_best_only=True, monitor='val_loss')\n",
    "\n",
    "# ── 학습 ───────────────────────────────────────────────────────────────\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=epochs,\n",
    "    callbacks=[early_stop, checkpoint]\n",
    ")\n",
    "\n",
    "# ── 평가/예측 및 리포트 ───────────────────────────────────────────────\n",
    "val_generator.reset()\n",
    "y_pred = model.predict(val_generator)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = val_generator.classes\n",
    "class_labels = list(val_generator.class_indices.keys())\n",
    "\n",
    "print(classification_report(y_true, y_pred_classes, target_names=class_labels))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
